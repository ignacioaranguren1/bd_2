{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ignacioaranguren1/bd_2/blob/main/bd_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install keras-tuner"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRHpdlhvUuei",
        "outputId": "7c07d8ef-c47f-4840-a73f-f66192d19ecd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras-tuner in /usr/local/lib/python3.7/dist-packages (1.1.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (21.3)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.8.0)\n",
            "Requirement already satisfied: kt-legacy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.0.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.21.6)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (5.5.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.23.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (0.7.5)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (2.6.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (4.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (4.4.2)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (0.8.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (1.0.18)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (57.4.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (5.1.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->keras-tuner) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->keras-tuner) (0.2.5)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->keras-tuner) (3.0.9)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->keras-tuner) (0.7.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2022.5.18.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (3.0.4)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.0.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.37.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (3.3.7)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.46.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.4.6)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (3.17.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.8.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->keras-tuner) (4.11.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner) (4.2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import os\n",
        "import keras_tuner\n",
        "import datetime as dt\n",
        "\n",
        "from tqdm import tqdm\n",
        "from datetime import datetime\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from keras_tuner.tuners import RandomSearch\n",
        "from tensorflow.keras.layers import BatchNormalization"
      ],
      "metadata": {
        "id": "dtScW94T_IUq"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFTNOBY5-SS5",
        "outputId": "3b55b0db-af42-43ae-fce8-02c3a4199d62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "\n",
        "datapath = r'/content/drive/MyDrive/bd2/data'\n",
        "os.chdir(datapath)"
      ],
      "metadata": {
        "id": "TOwQ1uv2-gsD"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUSZgH01c0gK"
      },
      "source": [
        "1.In the data used by Gu, Kelly and Xiu (RFS 2019 – provided in class), use a similar procedure to theirs to predict stock returns with neural networks. Start by finding a suitable baseline configuration, and use a validation procedure to pick optimal hyperparameters for three neural network models: One with 2 hidden layers, one with 3 hidden layers, and one with 4 hidden layers. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "JN8g2yI6c0gN"
      },
      "outputs": [],
      "source": [
        "data = pd.read_pickle('returns_chars_panel.pkl')\n",
        "macro = pd.read_pickle('macro_timeseries.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "uUS00_JCrz2m"
      },
      "outputs": [],
      "source": [
        "def train_validation_test_split(data,train_end_date,validation_end_date):\n",
        "  tmp = data.reset_index()\n",
        "  train = tmp[tmp.date<=train_end_date].set_index(['date','permno'],drop=True)\n",
        "  validation = tmp[(tmp.date>train_end_date) & (tmp.date<=validation_end_date)].set_index(['date','permno'],drop=True)\n",
        "  test = tmp[tmp.date>validation_end_date].set_index(['date','permno'],drop=True)\n",
        "  return train,validation,test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "2ZXV1zHXnrbV"
      },
      "outputs": [],
      "source": [
        "data_merged = pd.merge(data,macro,on=['date'])\n",
        "datelist = list(set(data_merged['date']))\n",
        "datelist.sort()\n",
        "data_merged.set_index(['date','permno'],drop=True,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "QKYOGMqDoGqO"
      },
      "outputs": [],
      "source": [
        "# It is worth mentioning that even though we have set these ratios in order to split the data set the resulting\n",
        "# weighs are not exactly the same because dates can have more than one observation\n",
        "train_ratio = 0.5\n",
        "validation_ratio = 0.25\n",
        "train_date = datelist[int(len(datelist)*train_ratio)]\n",
        "validation_date = datelist[int(len(datelist)*(train_ratio+validation_ratio))]\n",
        "X = data_merged.iloc[:,3:].copy()\n",
        "y = data_merged['excess_ret'].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "JiHQP_Xmrv9s"
      },
      "outputs": [],
      "source": [
        "X_train,X_validation,X_test = train_validation_test_split(X,train_date,validation_date)\n",
        "y_train,y_validation,y_test = train_validation_test_split(y,train_date,validation_date)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "_6bgsQRe-SS-"
      },
      "outputs": [],
      "source": [
        "def keras_model(n_layers, units, learning_rate):\n",
        "    # Model definition separated from tuner in order to achieve modularity \n",
        "    # Build model\n",
        "    model = Sequential()\n",
        "    model.add(layers.Input(shape=(105,)))\n",
        "    # Add layers iteratively and assign a units hyperparam selector\n",
        "    for i in range(n_layers):\n",
        "        model.add(BatchNormalization()) # Normalizing before activation seems to yield better results than after\n",
        "        model.add(layers.Dense(units=units[0][i], activation='relu'))\n",
        "    model.add(layers.Dense(1, activation='linear'))\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "        loss='mse')\n",
        "    return model\n",
        "\n",
        "class HyperRegressor(keras_tuner.HyperModel):\n",
        "    def __init__(self, n_layers, *args, **kwargs):\n",
        "        # Pass all arguments except number of layers to parent\n",
        "        self.n_layers = n_layers\n",
        "        super().__init__(*args, **kwargs)\n",
        "\n",
        "    def build(self, hp):\n",
        "        # Hyperparameters choices and ranges definition \n",
        "        # To increase modularity, we declare units choice for each layer in a list \n",
        "        units=[hp.Int(f'units_{i + 1}',min_value=16,max_value=160,step=16) for i in range(self.n_layers)],\n",
        "        learning_rate = hp.Float(\"learning_rate\", min_value=1e-4, max_value=1e-2, sampling=\"log\")\n",
        "        return keras_model(self.n_layers, units, learning_rate)\n",
        "\n",
        "    def fit(self, hp, model, x, y, validation_data, **kwargs):\n",
        "        model.fit(x, y, **kwargs)\n",
        "        x_val, y_val = validation_data\n",
        "        y_pred = model.predict(x_val)\n",
        "        # Return a single float to minimize.\n",
        "        return np.mean((y_pred - y_val)**2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "zcQMs56h-SS_"
      },
      "outputs": [],
      "source": [
        "########################\n",
        "# CONSTANTS DEFINITION #\n",
        "########################\n",
        "\n",
        "MAX_TRIALS = 10\n",
        "EXECUTION_PER_TRIAL = 3\n",
        "EPOCHS = 8\n",
        "BATCH_SIZE = 256\n",
        "\n",
        "def tune_model(n_layers=2):\n",
        "  # Early stop if loss does not improve after 3 epochs\n",
        "  callback = keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
        "  tuner = RandomSearch(\n",
        "        hypermodel=HyperRegressor(n_layers),\n",
        "        max_trials=MAX_TRIALS,\n",
        "        executions_per_trial=EXECUTION_PER_TRIAL,\n",
        "        overwrite=True,\n",
        "        directory='bd_2',\n",
        "        project_name=f'NN_new_{n_layers}'\n",
        "  )\n",
        "  tuner.search(\n",
        "      X_train.values, \n",
        "      y_train.values,\n",
        "      validation_data=(X_validation.values, y_validation.values),\n",
        "      batch_size=BATCH_SIZE,\n",
        "      epochs=EPOCHS,\n",
        "      callbacks=[callback]\n",
        "  )\n",
        "  return tuner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GpUrwzRc-STA",
        "outputId": "37279b8d-7da6-4223-b843-c43910ca1408"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 10 Complete [00h 09m 28s]\n",
            "default_objective: 0.04740524855275794\n",
            "\n",
            "Best default_objective So Far: 0.04082417058268804\n",
            "Total elapsed time: 01h 34m 14s\n",
            "INFO:tensorflow:Oracle triggered exit\n"
          ]
        }
      ],
      "source": [
        "models = []\n",
        "parameters = []\n",
        "tuners = []\n",
        "for n in range(2,5):\n",
        "    tuner = tune_model(n)\n",
        "    parameters.append(tuner.get_best_hyperparameters)\n",
        "    models.append(tuner.get_best_models(1)[0])\n",
        "    tuners.append(tuner)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ow2WYyMr-STC",
        "outputId": "e6889abb-192f-4efe-e49c-1ff56279ab54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'units_1': 144, 'units_2': 64, 'learning_rate': 0.000256153969803113}\n",
            "{'units_1': 64, 'units_2': 96, 'units_3': 112, 'learning_rate': 0.0013688978213179357}\n",
            "{'units_1': 16, 'units_2': 48, 'units_3': 128, 'units_4': 144, 'learning_rate': 0.0005677736913894471}\n"
          ]
        }
      ],
      "source": [
        "for i in range(3):\n",
        "  print(tuners[i].get_best_hyperparameters()[0].values)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('models.pkl','wb') as f:\n",
        "  pickle.dump(models,f)\n",
        "with open('tuners.pkl','wb') as f:\n",
        "  pickle.dump(tuners,f)"
      ],
      "metadata": {
        "id": "nqljtYWpetKL",
        "outputId": "952c8ad6-e73a-4f62-ca6f-0ad2e65f249c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: ram://4cefee27-841d-4536-af97-baa27475d903/assets\n",
            "INFO:tensorflow:Assets written to: ram://96fedd41-dad1-4d05-aea2-d2ce631fd171/assets\n",
            "INFO:tensorflow:Assets written to: ram://b75f643e-f30a-4748-996b-531cb7f81058/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-_834O5-STB",
        "outputId": "daf82c26-0c93-43eb-e24c-721226e813cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/64\n",
            "14608/14608 [==============================] - 35s 2ms/step - loss: 0.0554\n",
            "Epoch 2/64\n",
            "14608/14608 [==============================] - 32s 2ms/step - loss: 0.0296\n",
            "Epoch 3/64\n",
            "14608/14608 [==============================] - 32s 2ms/step - loss: 0.0293\n",
            "Epoch 4/64\n",
            "14608/14608 [==============================] - 32s 2ms/step - loss: 0.0291\n",
            "Epoch 5/64\n",
            "14608/14608 [==============================] - 32s 2ms/step - loss: 0.0289\n",
            "Epoch 6/64\n",
            "14608/14608 [==============================] - 31s 2ms/step - loss: 0.0288\n",
            "Epoch 7/64\n",
            "14608/14608 [==============================] - 31s 2ms/step - loss: 0.0287\n",
            "Epoch 8/64\n",
            "14608/14608 [==============================] - 31s 2ms/step - loss: 0.0286\n",
            "Epoch 9/64\n",
            "14608/14608 [==============================] - 31s 2ms/step - loss: 0.0285\n",
            "Epoch 10/64\n",
            "14608/14608 [==============================] - 31s 2ms/step - loss: 0.0284\n",
            "Epoch 11/64\n",
            "14608/14608 [==============================] - 31s 2ms/step - loss: 0.0283\n",
            "Epoch 12/64\n",
            "14608/14608 [==============================] - 31s 2ms/step - loss: 0.0282\n",
            "Epoch 13/64\n",
            "14608/14608 [==============================] - 31s 2ms/step - loss: 0.0281\n",
            "Epoch 14/64\n",
            "14608/14608 [==============================] - 31s 2ms/step - loss: 0.0280\n",
            "Epoch 15/64\n",
            "14608/14608 [==============================] - 31s 2ms/step - loss: 0.0279\n",
            "Epoch 16/64\n",
            "14608/14608 [==============================] - 31s 2ms/step - loss: 0.0279\n",
            "Epoch 17/64\n",
            "14608/14608 [==============================] - 30s 2ms/step - loss: 0.0278\n",
            "Epoch 18/64\n",
            "14608/14608 [==============================] - 31s 2ms/step - loss: 0.0278\n",
            "Epoch 19/64\n",
            "14608/14608 [==============================] - 30s 2ms/step - loss: 0.0277\n",
            "Epoch 20/64\n",
            "14608/14608 [==============================] - 31s 2ms/step - loss: 0.0277\n",
            "Epoch 21/64\n",
            "14608/14608 [==============================] - 30s 2ms/step - loss: 0.0277\n",
            "Epoch 22/64\n",
            "14608/14608 [==============================] - 30s 2ms/step - loss: 0.0276\n",
            "Epoch 23/64\n",
            "14608/14608 [==============================] - 30s 2ms/step - loss: 0.0276\n",
            "Epoch 24/64\n",
            "14608/14608 [==============================] - 30s 2ms/step - loss: 0.0276\n",
            "Epoch 25/64\n",
            "14608/14608 [==============================] - 30s 2ms/step - loss: 0.0276\n",
            "Epoch 26/64\n",
            "14608/14608 [==============================] - 30s 2ms/step - loss: 0.0275\n",
            "Epoch 27/64\n",
            "14608/14608 [==============================] - 30s 2ms/step - loss: 0.0275\n",
            "Epoch 28/64\n",
            "14608/14608 [==============================] - 30s 2ms/step - loss: 0.0275\n",
            "Epoch 29/64\n",
            "14608/14608 [==============================] - 30s 2ms/step - loss: 0.0275\n",
            "Epoch 30/64\n",
            "14608/14608 [==============================] - 30s 2ms/step - loss: 0.0274\n",
            "Epoch 31/64\n",
            "14608/14608 [==============================] - 30s 2ms/step - loss: 0.0274\n",
            "Epoch 32/64\n",
            "14608/14608 [==============================] - 30s 2ms/step - loss: 0.0274\n",
            "Epoch 33/64\n",
            "14608/14608 [==============================] - 29s 2ms/step - loss: 0.0274\n",
            "Epoch 34/64\n",
            "14608/14608 [==============================] - 29s 2ms/step - loss: 0.0274\n",
            "Epoch 35/64\n",
            "14608/14608 [==============================] - 29s 2ms/step - loss: 0.0274\n",
            "Epoch 36/64\n",
            "14608/14608 [==============================] - 29s 2ms/step - loss: 0.0274\n",
            "Epoch 37/64\n",
            "14608/14608 [==============================] - 29s 2ms/step - loss: 0.0273\n",
            "Epoch 38/64\n",
            "14608/14608 [==============================] - 29s 2ms/step - loss: 0.0273\n",
            "Epoch 39/64\n",
            "14608/14608 [==============================] - 29s 2ms/step - loss: 0.0273\n",
            "Epoch 40/64\n",
            "14608/14608 [==============================] - 29s 2ms/step - loss: 0.0273\n",
            "Epoch 41/64\n",
            "14608/14608 [==============================] - 29s 2ms/step - loss: 0.0273\n",
            "Epoch 42/64\n",
            "14608/14608 [==============================] - 28s 2ms/step - loss: 0.0273\n",
            "Epoch 43/64\n",
            "14608/14608 [==============================] - 28s 2ms/step - loss: 0.0273\n",
            "Epoch 44/64\n",
            "14608/14608 [==============================] - 28s 2ms/step - loss: 0.0273\n",
            "Epoch 45/64\n",
            "14608/14608 [==============================] - 28s 2ms/step - loss: 0.0272\n",
            "Epoch 46/64\n",
            "14608/14608 [==============================] - 28s 2ms/step - loss: 0.0272\n",
            "Epoch 47/64\n",
            "14608/14608 [==============================] - 28s 2ms/step - loss: 0.0272\n",
            "Epoch 48/64\n",
            "14608/14608 [==============================] - 28s 2ms/step - loss: 0.0272\n",
            "Epoch 49/64\n",
            "14608/14608 [==============================] - 28s 2ms/step - loss: 0.0272\n",
            "Epoch 50/64\n",
            "14608/14608 [==============================] - 28s 2ms/step - loss: 0.0272\n",
            "Epoch 51/64\n",
            "14608/14608 [==============================] - 28s 2ms/step - loss: 0.0272\n",
            "Epoch 52/64\n",
            "14608/14608 [==============================] - 29s 2ms/step - loss: 0.0272\n",
            "Epoch 53/64\n",
            "14608/14608 [==============================] - 28s 2ms/step - loss: 0.0272\n",
            "Epoch 54/64\n",
            "14608/14608 [==============================] - 28s 2ms/step - loss: 0.0272\n",
            "Epoch 55/64\n",
            "14608/14608 [==============================] - 28s 2ms/step - loss: 0.0272\n",
            "Epoch 56/64\n",
            "14608/14608 [==============================] - 28s 2ms/step - loss: 0.0272\n",
            "Epoch 57/64\n",
            "14608/14608 [==============================] - 28s 2ms/step - loss: 0.0272\n",
            "Epoch 58/64\n",
            "14608/14608 [==============================] - 28s 2ms/step - loss: 0.0272\n",
            "Epoch 59/64\n",
            "14608/14608 [==============================] - 28s 2ms/step - loss: 0.0271\n",
            "Epoch 60/64\n",
            "14608/14608 [==============================] - 28s 2ms/step - loss: 0.0271\n",
            "Epoch 61/64\n",
            "14608/14608 [==============================] - 32s 2ms/step - loss: 0.0271\n",
            "Epoch 62/64\n",
            "14608/14608 [==============================] - 31s 2ms/step - loss: 0.0271\n",
            "Epoch 63/64\n",
            "14608/14608 [==============================] - 32s 2ms/step - loss: 0.0271\n",
            "Epoch 64/64\n",
            "14608/14608 [==============================] - 31s 2ms/step - loss: 0.0271\n",
            "4920/4920 [==============================] - 8s 2ms/step - loss: 0.0203\n",
            "4312/4312 [==============================] - 7s 2ms/step - loss: 0.0227\n",
            "5377/5377 [==============================] - 8s 2ms/step - loss: 0.0362\n",
            "Epoch 1/64\n",
            "14608/14608 [==============================] - 31s 2ms/step - loss: 0.0302\n",
            "Epoch 2/64\n",
            "14608/14608 [==============================] - 31s 2ms/step - loss: 0.0288\n",
            "Epoch 3/64\n",
            "14608/14608 [==============================] - 31s 2ms/step - loss: 0.0286\n",
            "Epoch 4/64\n",
            "14608/14608 [==============================] - 31s 2ms/step - loss: 0.0285\n",
            "Epoch 5/64\n",
            "14608/14608 [==============================] - 31s 2ms/step - loss: 0.0285\n",
            "Epoch 6/64\n",
            "14608/14608 [==============================] - 30s 2ms/step - loss: 0.0285\n",
            "Epoch 7/64\n",
            "14608/14608 [==============================] - 30s 2ms/step - loss: 0.0284\n",
            "Epoch 8/64\n",
            "14608/14608 [==============================] - 30s 2ms/step - loss: 0.0284\n",
            "Epoch 9/64\n",
            "14608/14608 [==============================] - 30s 2ms/step - loss: 0.0284\n",
            "Epoch 10/64\n",
            "14608/14608 [==============================] - 30s 2ms/step - loss: 0.0284\n",
            "Epoch 11/64\n",
            "14608/14608 [==============================] - 30s 2ms/step - loss: 0.0284\n",
            "Epoch 12/64\n",
            "14608/14608 [==============================] - 30s 2ms/step - loss: 0.0284\n",
            "Epoch 13/64\n",
            "14608/14608 [==============================] - 30s 2ms/step - loss: 0.0284\n",
            "Epoch 14/64\n",
            "14608/14608 [==============================] - 30s 2ms/step - loss: 0.0284\n",
            "Epoch 15/64\n",
            "14608/14608 [==============================] - 30s 2ms/step - loss: 0.0284\n",
            "Epoch 16/64\n",
            "14608/14608 [==============================] - 30s 2ms/step - loss: 0.0284\n",
            "4920/4920 [==============================] - 7s 1ms/step - loss: 0.0217\n",
            "4312/4312 [==============================] - 6s 1ms/step - loss: 0.0243\n",
            "5377/5377 [==============================] - 8s 1ms/step - loss: 0.0379\n",
            "Epoch 1/64\n",
            "14608/14608 [==============================] - 31s 2ms/step - loss: 0.0315\n",
            "Epoch 2/64\n",
            "14608/14608 [==============================] - 30s 2ms/step - loss: 0.0281\n",
            "Epoch 3/64\n",
            "14608/14608 [==============================] - 30s 2ms/step - loss: 0.0273\n",
            "Epoch 4/64\n",
            "14608/14608 [==============================] - 30s 2ms/step - loss: 0.0270\n",
            "Epoch 5/64\n",
            "14608/14608 [==============================] - 30s 2ms/step - loss: 0.0268\n",
            "Epoch 6/64\n",
            "14608/14608 [==============================] - 30s 2ms/step - loss: 0.0266\n",
            "Epoch 7/64\n",
            "14608/14608 [==============================] - 30s 2ms/step - loss: 0.0265\n",
            "Epoch 8/64\n",
            "14608/14608 [==============================] - 30s 2ms/step - loss: 0.0265\n",
            "Epoch 9/64\n",
            "14608/14608 [==============================] - 30s 2ms/step - loss: 0.0264\n",
            "Epoch 10/64\n",
            "14608/14608 [==============================] - 30s 2ms/step - loss: 0.0264\n",
            "Epoch 11/64\n",
            "14608/14608 [==============================] - 30s 2ms/step - loss: 0.0263\n",
            "Epoch 12/64\n",
            "14608/14608 [==============================] - 30s 2ms/step - loss: 0.0263\n",
            "Epoch 13/64\n",
            "14608/14608 [==============================] - 29s 2ms/step - loss: 0.0263\n",
            "Epoch 14/64\n",
            "14608/14608 [==============================] - 29s 2ms/step - loss: 0.0262\n",
            "Epoch 15/64\n",
            "14608/14608 [==============================] - 29s 2ms/step - loss: 0.0262\n",
            "Epoch 16/64\n",
            "14608/14608 [==============================] - 29s 2ms/step - loss: 0.0262\n",
            "Epoch 17/64\n",
            "14608/14608 [==============================] - 29s 2ms/step - loss: 0.0262\n",
            "Epoch 18/64\n",
            "14608/14608 [==============================] - 29s 2ms/step - loss: 0.0261\n",
            "Epoch 19/64\n",
            "14608/14608 [==============================] - 29s 2ms/step - loss: 0.0261\n",
            "Epoch 20/64\n",
            "14608/14608 [==============================] - 30s 2ms/step - loss: 0.0261\n",
            "Epoch 21/64\n",
            "14608/14608 [==============================] - 30s 2ms/step - loss: 0.0261\n",
            "Epoch 22/64\n",
            "14608/14608 [==============================] - 31s 2ms/step - loss: 0.0261\n",
            "Epoch 23/64\n",
            "14608/14608 [==============================] - 30s 2ms/step - loss: 0.0261\n",
            "Epoch 24/64\n",
            "14608/14608 [==============================] - 30s 2ms/step - loss: 0.0260\n",
            "Epoch 25/64\n",
            "14608/14608 [==============================] - 30s 2ms/step - loss: 0.0260\n",
            "Epoch 26/64\n",
            "14608/14608 [==============================] - 29s 2ms/step - loss: 0.0260\n",
            "Epoch 27/64\n",
            "14608/14608 [==============================] - 29s 2ms/step - loss: 0.0260\n",
            "Epoch 28/64\n",
            "14608/14608 [==============================] - 29s 2ms/step - loss: 0.0260\n",
            "Epoch 29/64\n",
            "14608/14608 [==============================] - 29s 2ms/step - loss: 0.0260\n",
            "Epoch 30/64\n",
            "14608/14608 [==============================] - 29s 2ms/step - loss: 0.0260\n",
            "Epoch 31/64\n",
            "14608/14608 [==============================] - 29s 2ms/step - loss: 0.0260\n",
            "Epoch 32/64\n",
            "14608/14608 [==============================] - 29s 2ms/step - loss: 0.0259\n",
            "Epoch 33/64\n",
            "14608/14608 [==============================] - 29s 2ms/step - loss: 0.0259\n",
            "Epoch 34/64\n",
            "14608/14608 [==============================] - 29s 2ms/step - loss: 0.0259\n",
            "Epoch 35/64\n",
            "14608/14608 [==============================] - 29s 2ms/step - loss: 0.0259\n",
            "Epoch 36/64\n",
            "14608/14608 [==============================] - 29s 2ms/step - loss: 0.0259\n",
            "Epoch 37/64\n",
            "14608/14608 [==============================] - 29s 2ms/step - loss: 0.0259\n",
            "Epoch 38/64\n",
            "14608/14608 [==============================] - 29s 2ms/step - loss: 0.0259\n",
            "Epoch 39/64\n",
            "14608/14608 [==============================] - 29s 2ms/step - loss: 0.0259\n",
            "Epoch 40/64\n",
            "14608/14608 [==============================] - 29s 2ms/step - loss: 0.0259\n",
            "Epoch 41/64\n",
            "14608/14608 [==============================] - 29s 2ms/step - loss: 0.0259\n",
            "Epoch 42/64\n",
            "14608/14608 [==============================] - 29s 2ms/step - loss: 0.0259\n",
            "4920/4920 [==============================] - 7s 1ms/step - loss: 0.0191\n",
            "4312/4312 [==============================] - 6s 1ms/step - loss: 0.0217\n",
            "5377/5377 [==============================] - 8s 1ms/step - loss: 0.0343\n"
          ]
        }
      ],
      "source": [
        "def format_units(buffer_dict):\n",
        "      # Convert units param to a list of units to match processing formatting\n",
        "      units = []\n",
        "      # Check if key is unit, if it is add to list \n",
        "      for key, value  in buffer_dict.values.items():\n",
        "          if 'units' in key:\n",
        "              units += [value]\n",
        "      # Crate new dict with correct format \n",
        "      best_params = {}\n",
        "      best_params['units'] = [units]\n",
        "      best_params['learning_rate'] = buffer_dict['learning_rate']\n",
        "      return best_params\n",
        "\n",
        "models_refitted = []\n",
        "results = {}\n",
        "for i in range(3):\n",
        "    # Build and refit model with best params\n",
        "    callback = keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
        "    best_hps = format_units(tuners[i].get_best_hyperparameters()[0])\n",
        "    n_layers = len(best_hps['units']) # Get num of hidden layers\n",
        "    model = keras_model(n_layers, **best_hps) # Rebuild model\n",
        "    model.fit(X, y, epochs=64, batch_size=256,verbose=True, callbacks=[callback])\n",
        "    models_refitted.append(model)\n",
        "    # Evaluate train, val and test \n",
        "    train_result = model.evaluate(X_train.values,y_train.values,batch_size=256)\n",
        "    test_result = model.evaluate(X_test.values,y_test.values,batch_size=256)\n",
        "    val_result = model.evaluate(X_validation.values,y_validation.values,batch_size=256)\n",
        "    results[f'NN{i + 1}'] = {'train': train_result, 'validation': val_result, 'test': test_result}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ywo6kW_j-STC",
        "outputId": "62d58504-ee46-47c5-be12-7db06eebd4f0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'NN1': {'test': 0.024710332974791527,\n",
              "  'train': 0.02167060784995556,\n",
              "  'validation': 0.03952166065573692},\n",
              " 'NN2': {'test': 0.023484626784920692,\n",
              "  'train': 0.021047215908765793,\n",
              "  'validation': 0.037058476358652115},\n",
              " 'NN3': {'test': 0.023973975330591202,\n",
              "  'train': 0.021303806453943253,\n",
              "  'validation': 0.03852330520749092}}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NujnDpUp-STD",
        "outputId": "6c1f4d65-88f0-4028-9168-16c58d824fec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: ram://badb6e86-648e-47cd-a306-01eaf114f5b5/assets\n",
            "INFO:tensorflow:Assets written to: ram://b003ddc8-fec3-4294-8f3f-28fbafbf577b/assets\n",
            "INFO:tensorflow:Assets written to: ram://21149ecd-ca54-4391-b42a-2d8bc73ff3c4/assets\n"
          ]
        }
      ],
      "source": [
        "with open('refitted_models_BN.pkl','wb') as f:\n",
        "  pickle.dump(models_refitted,f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CP73ewuxc0gT"
      },
      "source": [
        "2.Use test data to get an idea of the out of sample performance of each model. Convert the standard MSE metric for out of sample performance to the “R2 out of sample” metric that was discussed in class. Compare your results to those in Gu-Kelly-Xiu and comment on the differences. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "0KZ3qleF-STE"
      },
      "outputs": [],
      "source": [
        "with open('models.pkl','rb') as f:\n",
        "  models = pickle.load(f)\n",
        "with open('tuners.pkl','rb') as f:\n",
        "  tuners = pickle.load(f)\n",
        "with open('refitted_models_BN.pkl','rb') as f:\n",
        "  models_refitted = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def r_squared(y_pred, y_test):\n",
        "    return 1 - np.sum((y_test - y_pred)**2) / np.sum(y_test**2)"
      ],
      "metadata": {
        "id": "lfCN6eZImqbB"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "vRGwEta1c0gU"
      },
      "outputs": [],
      "source": [
        "rankings = X_test['mvel1'].groupby(['date']).rank()\n",
        "top_X_test = X_test.loc[rankings<=1000,:].values\n",
        "top_y_test = y_test.loc[rankings<=1000,:].values\n",
        "rankings_reverse = X_test['mvel1'].groupby(['date']).rank(ascending=False)\n",
        "bottom_X_test = X_test.loc[rankings_reverse<=1000,:].values\n",
        "bottom_y_test = y_test.loc[rankings_reverse<=1000,:].values\n",
        "\n",
        "R2_oos_df = pd.DataFrame(columns = ['R2_OOS','R2_OOS_top1000','R2_OOS_low1000'],index = ['NN2','NN3','NN4'])\n",
        "for i in range(3):\n",
        "    y_pred_all = models_refitted[i].predict(X_test,batch_size=256).reshape(-1,1)\n",
        "    y_pred_top = models_refitted[i].predict(top_X_test,batch_size=256).reshape(-1,1)\n",
        "    y_pred_bottom = models_refitted[i].predict(bottom_X_test,batch_size=256).reshape(-1,1)\n",
        "    \n",
        "    row = [r_squared(y_pred_all, y_test)[0],\n",
        "           r_squared(y_pred_top, top_y_test),\n",
        "           r_squared(y_pred_bottom, bottom_y_test)]\n",
        "    \n",
        "    R2_oos_df.iloc[i]= row"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "FqetXnyy-STE",
        "outputId": "56f3ca8f-c36b-4599-f6e4-47cc2ef6a500"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        R2_OOS R2_OOS_top1000 R2_OOS_low1000\n",
              "NN2  11.614579       7.251403      21.135385\n",
              "NN3   5.597416       4.051352       8.421495\n",
              "NN4  15.510674      10.886926      26.439364"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-489296c3-390a-485c-ad69-f11e28d137e6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>R2_OOS</th>\n",
              "      <th>R2_OOS_top1000</th>\n",
              "      <th>R2_OOS_low1000</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>NN2</th>\n",
              "      <td>11.614579</td>\n",
              "      <td>7.251403</td>\n",
              "      <td>21.135385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NN3</th>\n",
              "      <td>5.597416</td>\n",
              "      <td>4.051352</td>\n",
              "      <td>8.421495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NN4</th>\n",
              "      <td>15.510674</td>\n",
              "      <td>10.886926</td>\n",
              "      <td>26.439364</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-489296c3-390a-485c-ad69-f11e28d137e6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-489296c3-390a-485c-ad69-f11e28d137e6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-489296c3-390a-485c-ad69-f11e28d137e6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "R2_oos_df * 100"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('r_squared.pkl','wb') as f:\n",
        "  pickle.dump(R2_oos_df,f)"
      ],
      "metadata": {
        "id": "kZRdfWlolRMs"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eV0nT10sc0gU"
      },
      "source": [
        "3.Pick the model that performs the best out of sample, and interpret its output by doing the following analysis of variable importance:\n",
        "a.\tFirst, for all stock characteristics, get variable importance by setting one predictor at a time to zero and finding the decrease in out of sample R2. Show a table of the 10 most important variables according to this measure, and give an economic interpretation. \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('refitted_models_BN.pkl','rb') as f:\n",
        "  models_refitted = pickle.load(f)\n",
        "with open('r_squared.pkl','rb') as f:\n",
        "  R2_oos_df = pickle.load(f)"
      ],
      "metadata": {
        "id": "e4FNMTJvlgxL"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X_test.groupby(pd.Grouper(freq='M'))['mvel1'].rank()\n",
        "best_r_squared = max(R2_oos_df.iloc[:,0])\n",
        "best_r_squared * 100"
      ],
      "metadata": {
        "id": "VDzLErv3la-6",
        "outputId": "1845a8c3-8a17-477e-b1dc-08cc0738b9a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15.510674225049337"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OcByPQb-STG",
        "outputId": "13af639f-6184-44ea-c1e6-5fab55ed5246"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 67%|██████▋   | 70/105 [07:18<04:47,  8.21s/it]"
          ]
        }
      ],
      "source": [
        "feature_importance = {}\n",
        "for column_name in tqdm(X_train.columns):\n",
        "    X_tmp = X_test.copy()\n",
        "    X_tmp[column_name] = 0\n",
        "    y_pred_temp = models_refitted[2].predict(X_tmp, batch_size=256).reshape(-1,1)\n",
        "    feature_importance[column_name] = best_r_squared - r_squared(y_pred_temp, y_test)[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "importance_df = pd.DataFrame.from_dict(feature_importance, orient='index', columns=['magnitude'])\n",
        "# Retrieve 10 most significant\n",
        "df_10 = importance_df.sort_values('magnitude').iloc[(len(importance_df['magnitude']) - 10):,]\n",
        "\n",
        "df_10.index.values"
      ],
      "metadata": {
        "id": "4Qd44pW9SLeU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display chart\n",
        "plt.figure(figsize=(20,5))\n",
        "plt.barh(np.arange(len(df_10)),df_10.magnitude.values)\n",
        "plt.yticks(np.arange(len(df_10)),df_10.index.values)\n",
        "plt.title('Feature Importance',size=16)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Lh8WKrOaSNBN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sc-gagOLc0gV"
      },
      "source": [
        "b.\tSecond, get a measure of the joint importance of all our “macro predictors” (i.e., those taken from Welch and Goyal 2008), by setting them all to zero and finding the decrease in out of sample R2. Comment on how important macroeconomic variables are relative to stock characteristics in predicting returns. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AX8kVzNQc0gV"
      },
      "source": [
        "c.\tRepeat the two steps above, but by using a measure of the sensitivity of predictions to each input variable, as outlined in the lectures."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AzS8KJBWc0gV"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfTmKAXRc0gV"
      },
      "source": [
        "4.Fit a penalised linear model (LASSO) to the same data, using validation data to pick the best penalty (e.g., you can use the “sklearn” package in Python to do this easily). Compare its test data performance to the neural network. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yOkXRm3Oc0gW"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqsoN75nc0gW"
      },
      "source": [
        "5.Suppose somebody tells you to collect 10 more micro or macro variables that can predict returns and are not in our current dataset. How would you choose those variables, based on the intuitions you have gained in this project?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ni5ZNgXY1uGA"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jXNJN_hNc0gW"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "bd_2.ipynb",
      "provenance": [],
      "history_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "oldHeight": 123,
      "position": {
        "height": "377px",
        "left": "553px",
        "right": "20px",
        "top": "104px",
        "width": "602px"
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "varInspector_section_display": "block",
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}